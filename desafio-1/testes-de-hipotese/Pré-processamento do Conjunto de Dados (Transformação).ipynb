{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3abf6bb9",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> \n",
    "        Pré-processamento do Conjunto de Dados (Transformação)\n",
    "    </h1>\n",
    "</center>\n",
    "    <div style=\"text-align: right;\"><h3>\n",
    "        Carlos Eduardo Cassimiro da Silva\n",
    "    </h3></div>\n",
    "\n",
    "<center>\n",
    "    <h4>Neste notebook, iremos criar e aplicar o pipeline do pré-processamento das imagens, compilando todos os métodos estudados e verificados anteriormente. O objetivo do pré-processamento é transformar as imagens em histogramas, também tratando as amostras escuras antes disso. </h4>\n",
    "    Link do dataset: https://github.com/ricardobnjunior/Brazilian-Identity-Document-Dataset\n",
    "</center>\n",
    "\n",
    "<h4>Desafio #1: Classificação de documentos (RG, CNH e CPF) </h4>\n",
    "\n",
    " - Contextualização: Inúmeras áreas de diferentes organizações (usualmente como parte de um processo de um backoffice) recepcionam documentos dos seus clientes para formação de kits de documentação. Tais kits são, por exemplo, compartilhados com outros stakeholders das empresas. Conforme pode-se pressupor, um desafio nesse cenário refere-se ao fato de que o cliente pode enviar documentos, porém sem necessariamente indicar a qual tipo se o documento se refere (RG, CNH ou CPF, por exemplo). Dessa forma, ao invés de demandar um trabalho manual para essa leitura e classificação dos documentos, podemos construir um modelo de aprendizado que tenha capacidade de ler um conjunto de documentos (em .jpg, por exemplo) e, subsequentemente, realizar a classificação em três tipos distintos: RG, CNH e CPF.\n",
    " - Dataset: Para esse desafio utilizaremos um dataset público de RG, CNH e CPF (incluindo as imagens). Este repositório apresenta o conjunto de dados denominado Brazilian Identity Document Dataset (BID Dataset), o primeiro conjunto de dados público de documentos de identificação brasileiros. <br>\n",
    "\n",
    "<h4>Roteiro</h4>\n",
    "Módulos utilizados <br>\n",
    "1. Funções extras <br>\n",
    "2. Pipeline da transformação e tratamento das imagens <br>\n",
    "3. Aplicando o pipeline em todas as imagens <br>\n",
    "4. Salvando o conjunto de dados transformado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469dbd3",
   "metadata": {},
   "source": [
    "##### Módulos utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d53633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from sys import getsizeof\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d43e1",
   "metadata": {},
   "source": [
    "# 1. Funções extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d1b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe_func(img):\n",
    "    r, g, b = cv2.split(img)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    red = clahe.apply(r)\n",
    "    green = clahe.apply(g)\n",
    "    blue = clahe.apply(b)\n",
    "    return cv2.merge((red, green, blue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ef55b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_brightness_percent(img, percent):\n",
    "    r, g, b = cv2.split(img)\n",
    "    return cv2.merge((r*(percent*1.002989), g*(percent*1.005870), b*(percent*1.001140))).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6af7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_movel(hist, n):\n",
    "    medias_suavizada = []\n",
    "    tam = len(hist)\n",
    "\n",
    "    for i in range(tam-n):\n",
    "        soma = 0\n",
    "        for j in range(n):\n",
    "            soma += hist[i+j]\n",
    "        medias_suavizada.append(soma/n)\n",
    "        \n",
    "    for i in range(tam-1,tam-n,-1):\n",
    "        soma = 0\n",
    "        for j in range(n):\n",
    "            soma += hist[i-j]\n",
    "        medias_suavizada.append(soma/n)\n",
    "    \n",
    "    return medias_suavizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b093991e",
   "metadata": {},
   "source": [
    "# 2. Pipeline da transformação e tratamento das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b1cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepross(image):\n",
    "    ksize = (70,70) # Máscara do borramento\n",
    "\n",
    "    image_hsv = cv2.cvtColor(image,cv2.COLOR_RGB2HSV) # Transformando no formato HSV\n",
    "    H, _, V =  cv2.split(image_hsv) # Pegando apenas os valores de Hue e Value\n",
    "\n",
    "    # Verificando se a imagem é escura a partir do Value do HSV\n",
    "    if np.mean(V) < 175: # Valor obtido experimentalmente no teste 1.5\n",
    "        # Em caso positivo, aplicamos as técticas de melhoramento (teste 1.1,1.2 e 1.10)\n",
    "        image = increase_brightness_percent(image, 1.45)\n",
    "        image = clahe_func(image)\n",
    "        \n",
    "    image = cv2.blur(image, ksize) # Em seguida, aplicamos o borramento (teste 1.10)\n",
    "\n",
    "    # Após melhorar as amostras escuras, criamos os histogramas (teste 1)\n",
    "    hist = []\n",
    "    hist.append(cv2.calcHist(image,[0],None,[256],[0,256]))\n",
    "    hist.append(cv2.calcHist(image,[1],None,[256],[0,256]))\n",
    "    hist.append(cv2.calcHist(image,[2],None,[256],[0,256]))\n",
    "\n",
    "    # E aplicamos a normalização dos mesmos (teste 3)\n",
    "    for i in range(0,3):\n",
    "        mm = MinMaxScaler()\n",
    "        hist[i] = mm.fit_transform(hist[i], hist[i])\n",
    "        hist[i] = media_movel(hist[i],5)\n",
    "    \n",
    "    # O cv2.calcHist gera uma lista de lista, precisamos deixar todos os valores em uma única lista\n",
    "    for i in range(3):\n",
    "        temp = []\n",
    "        for j in range(len(hist[i])):\n",
    "            temp.append(hist[i][j][0])\n",
    "        hist[i] = media_movel(temp,5) # Aproveitando para suavizar os \"picos\" com a média móvel (teste 1.9)\n",
    "    \n",
    "    # Também testaremos acrescentar o começo do Hue do HSV no \"sinal\" (teste 1.8)\n",
    "    img_hsv =  cv2.split(cv2.cvtColor(image,cv2.COLOR_RGB2HSV))\n",
    "    H = cv2.calcHist(img_hsv,[0],None,[256],[0,256]) # Computando o histograma\n",
    "    \n",
    "    # Ajustando o formato da lista\n",
    "    temp = []\n",
    "    for j in range(len(H)):\n",
    "        temp.append(H[i][0])\n",
    "    \n",
    "    mm = MinMaxScaler()\n",
    "    H = mm.fit_transform(H, H)\n",
    "    H = media_movel(H,5)\n",
    "    \n",
    "    # Opção 1: submeter ao modelo somente os histogramas do RGB\n",
    "    opt1 = hist[0][4:]+hist[1][4:]+hist[2][4:]\n",
    "    # Opção 2: submeter ao modelo o histograma do RGB + uma faixa do H do HSV\n",
    "    opt2 = opt1+H[:100]\n",
    "    \n",
    "    return opt1, opt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d7573",
   "metadata": {},
   "source": [
    "# 3. Aplicando o pipeline em todas as imagens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d687ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'imagens_originais/BID_Dataset/' # caminho do diretório\n",
    "folders = os.listdir(path) # os.listdir lista todos os arquivos ou pastas dentro do referido diretório \n",
    "op1 = [] # Iremos testas duas opções de dados de treinamento a primeira com os canais do RGB\n",
    "op2 = [] # e a segunda com RGB + 100 primeiros valores do Hue do HSV\n",
    "y8 = [] # Também testaremos diferentes targets da classificação para verificar as diferenças\n",
    "# Não salvei no pré processamento, mas também testaresmo o treinamento com somente os 100 primeiros valores do HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "858939c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in folders:   # Percore cada pasta\n",
    "    if i == 'desktop.ini' :   # Pula esse arquivo oculto do sistema\n",
    "        continue\n",
    "    path_att = path+i+'/'    # Atualiza a string do caminho adicionando o nome da pasta\n",
    "    images = os.listdir(path_att)     # \"Puxa\" o nome dos arquivos da pasta\n",
    "    for j in range(2,len(images),3): # Laço para pegar os documentos. Como queremos só as imagens dos documentos,\n",
    "        img = cv2.imread(path_att+images[j])                                  # então pulamos de 3 em 3 arquivos\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    # Converte para RGB\n",
    "        opt1, opt2 = prepross(img)   # Aplica o pré-processamento na imagem\n",
    "        op1.append(opt1)  # Salva a opção de treinamento 1\n",
    "        op2.append(opt2)  # Salva a opção de treinamento 2\n",
    "        y8.append(i) # Salva o y com 8 targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0400b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com a lista de 8 targets, podemos criar as listas com os outros targets\n",
    "y3 = []\n",
    "y6 = []\n",
    "y7 = []\n",
    "for i in y8: # Em um único laço, faremos todas as listas com os diferentes targets\n",
    "    if (i == 'CNH_Aberta') or (i == 'RG_Aberto'):\n",
    "        y7.append('GRANDE') # Separa os 6 tipos de documentos dos abertos\n",
    "    else:\n",
    "        y7.append(i)\n",
    "    # Separada em 3 tipos de documento, incluindo os abertos\n",
    "    if (i=='CNH_Aberta') or (i =='CNH_Frente') or (i=='CNH_Verso'):\n",
    "        y3.append('CNH')\n",
    "    elif (i=='RG_Aberto') or (i =='RG_Frente') or (i=='RG_Verso'):\n",
    "        y3.append('RG')\n",
    "    else:\n",
    "        y3.append('CPF')\n",
    "    # Separa em 6 tipos de documentos\n",
    "    if (i=='CNH_Aberta'):\n",
    "        y6.append('CNH_Frente')\n",
    "    elif (i=='RG_Aberto'):\n",
    "        y6.append('RG_Frente')\n",
    "    else:\n",
    "        y6.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2262a",
   "metadata": {},
   "source": [
    "# 4. Salvando o conjunto de dados transformado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3252aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optei em salvar os arquivos em um dicinário (e depois JSON) pela comonidade dos dicionários\n",
    "data = {'opt1': op1, 'op2':op2, 'y3':y3,'y6':y6,'y7':y7,'y8':y8}\n",
    "\n",
    "with open('imagens_originais/desafio1_data2.json', 'w') as outfile: # Salvando os dados em formato JSON em um arquivo\n",
    "    json.dump(data, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
